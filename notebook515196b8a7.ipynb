{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:31:23.403071Z","iopub.execute_input":"2025-06-30T05:31:23.403295Z","iopub.status.idle":"2025-06-30T05:31:26.354975Z","shell.execute_reply.started":"2025-06-30T05:31:23.403273Z","shell.execute_reply":"2025-06-30T05:31:26.354040Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nserving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntrain_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:31:51.383278Z","iopub.execute_input":"2025-06-30T05:31:51.383613Z","iopub.status.idle":"2025-06-30T05:31:51.453429Z","shell.execute_reply.started":"2025-06-30T05:31:51.383591Z","shell.execute_reply":"2025-06-30T05:31:51.452397Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n5                                   Moran, Mr. James    male   NaN      0   \n6                            McCarthy, Mr. Timothy J    male  54.0      0   \n7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n5      0            330877   8.4583   NaN        Q  \n6      0             17463  51.8625   E46        S  \n7      1            349909  21.0750   NaN        S  \n8      2            347742  11.1333   NaN        S  \n9      0            237736  30.0708   NaN        C  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Moran, Mr. James</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>McCarthy, Mr. Timothy J</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Palsson, Master. Gosta Leonard</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n        \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\n    \npreprocessed_train_df = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\n\npreprocessed_train_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:32:11.522256Z","iopub.execute_input":"2025-06-30T05:32:11.522599Z","iopub.status.idle":"2025-06-30T05:32:11.547316Z","shell.execute_reply.started":"2025-06-30T05:32:11.522573Z","shell.execute_reply":"2025-06-30T05:32:11.546537Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                              Name     Sex   Age  SibSp  \\\n0                            Braund Mr Owen Harris    male  22.0      1   \n1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                             Heikkinen Miss Laina  female  26.0      0   \n3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                           Allen Mr William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1      0          PC 17599  71.2833   C85        C         17599          PC  \n2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3      0            113803  53.1000  C123        S        113803        NONE  \n4      0            373450   8.0500   NaN        S        373450        NONE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_number</th>\n      <th>Ticket_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"input_features = list(preprocessed_train_df.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n#input_features.remove(\"Ticket_number\")\n\nprint(f\"Input features: {input_features}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:32:26.668646Z","iopub.execute_input":"2025-06-30T05:32:26.668972Z","iopub.status.idle":"2025-06-30T05:32:26.674793Z","shell.execute_reply.started":"2025-06-30T05:32:26.668949Z","shell.execute_reply":"2025-06-30T05:32:26.673797Z"}},"outputs":[{"name":"stdout","text":"Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def tokenize_names(features, labels=None):\n    \"\"\"Divite the names into tokens. TF-DF can consume text tokens natively.\"\"\"\n    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n    return features, labels\n\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df,label=\"Survived\").map(tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:34:06.139639Z","iopub.execute_input":"2025-06-30T05:34:06.140205Z","iopub.status.idle":"2025-06-30T05:34:06.449085Z","shell.execute_reply.started":"2025-06-30T05:34:06.140181Z","shell.execute_reply":"2025-06-30T05:34:06.447781Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n2025-06-30 05:34:06.172491: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    random_seed=1234,\n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:34:11.278257Z","iopub.execute_input":"2025-06-30T05:34:11.278944Z","iopub.status.idle":"2025-06-30T05:34:17.772665Z","shell.execute_reply.started":"2025-06-30T05:34:11.278916Z","shell.execute_reply":"2025-06-30T05:34:17.771699Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751261655.735418      35 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1751261655.736896      35 kernel.cc:783] Collect training examples\nI0000 00:00:1751261655.736924      35 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1751261655.737954      35 kernel.cc:401] Number of batches: 1\nI0000 00:00:1751261655.737983      35 kernel.cc:402] Number of examples: 891\nI0000 00:00:1751261655.739005      35 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261655.739614      35 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261655.739861      35 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261655.740156      35 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261655.740906      35 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1751261655.741013      35 kernel.cc:818] Configure learner\nI0000 00:00:1751261655.741440      35 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 1234\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 6\n    min_examples: 5\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    axis_aligned_split {\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n  }\n  shrinkage: 0.1\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1751261655.741929      35 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmp80ikmpmo/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1751261655.742147     110 kernel.cc:895] Train model\nI0000 00:00:1751261656.106279     110 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.860894\nI0000 00:00:1751261656.111090     110 kernel.cc:926] Export model in log directory: /tmp/tmp80ikmpmo with prefix 97e7600929854351\nI0000 00:00:1751261656.114565     110 kernel.cc:944] Save model in resources\nI0000 00:00:1751261656.117780      35 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 0.860894\n\nAccuracy: 0.826087  CI95[W][0 1]\nErrorRate: : 0.173913\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  47   3\n2  13  29\nTotal: 92\n\n\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1751261656.162626      35 quick_scorer_extended.cc:922] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\nI0000 00:00:1751261656.163166      35 abstract_model.cc:1404] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8260869383811951 Loss:0.8608942627906799\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nprint(f\"Found TF-DF {tfdf.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:33:13.937183Z","iopub.execute_input":"2025-06-30T05:33:13.937544Z","iopub.status.idle":"2025-06-30T05:33:39.436106Z","shell.execute_reply.started":"2025-06-30T05:33:13.937519Z","shell.execute_reply":"2025-06-30T05:33:39.435091Z"}},"outputs":[{"name":"stderr","text":"2025-06-30 05:33:16.833124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751261597.211969      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751261597.311674      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n        Decision Forests</a> using the same algorithms but with more features and faster\n    training!\n</p>\n<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n        <p\n            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n            Old code</p>\n        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\nimport tensorflow_decision_forests as tfdf\n\ntf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\nmodel = tfdf.keras.RandomForestModel(label=\"l\")\nmodel.fit(tf_ds)\n</pre>\n    </div>\n    <div style=\"width: 5px;\"></div>\n    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n        <p\n            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n            New code</p>\n        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\nimport ydf\n\nmodel = ydf.RandomForestLearner(label=\"l\").train(ds)\n</pre>\n    </div>\n</div>\n<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n        guide</a>)</p>\n"},"metadata":{}},{"name":"stdout","text":"Found TF-DF 1.11.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True,\n        min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n    sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234,\n    \n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:35:46.459049Z","iopub.execute_input":"2025-06-30T05:35:46.460220Z","iopub.status.idle":"2025-06-30T05:35:48.046901Z","shell.execute_reply.started":"2025-06-30T05:35:46.460187Z","shell.execute_reply":"2025-06-30T05:35:48.045740Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1751261746.861564      35 kernel.cc:782] Start Yggdrasil model training\nI0000 00:00:1751261746.861611      35 kernel.cc:783] Collect training examples\nI0000 00:00:1751261746.861626      35 kernel.cc:795] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: CATEGORICAL\n  categorial {\n    min_vocab_frequency: 0\n    max_vocab_count: -1\n  }\n}\ncolumn_guides {\n  column_name_pattern: \"^Pclass$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Name$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Sex$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Age$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^SibSp$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Parch$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Fare$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Cabin$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Embarked$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_number$\"\n}\ncolumn_guides {\n  column_name_pattern: \"^Ticket_item$\"\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: true\ndetect_numerical_as_discretized_numerical: false\n\nI0000 00:00:1751261746.862117      35 kernel.cc:401] Number of batches: 1\nI0000 00:00:1751261746.862136      35 kernel.cc:402] Number of examples: 891\nI0000 00:00:1751261746.863179      35 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261746.863828      35 data_spec_inference.cc:354] 1441 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Name (85 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261746.864066      35 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261746.864375      35 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\nI0000 00:00:1751261746.865116      35 kernel.cc:802] Training dataset:\nNumber of records: 891\nNumber of columns: 12\n\nNumber of columns by type:\n\tCATEGORICAL: 6 (50%)\n\tNUMERICAL: 5 (41.6667%)\n\tCATEGORICAL_SET: 1 (8.33333%)\n\nColumns:\n\nCATEGORICAL: 6 (50%)\n\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n\nNUMERICAL: 5 (41.6667%)\n\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n\nCATEGORICAL_SET: 1 (8.33333%)\n\t4: \"Name\" CATEGORICAL_SET has-dict vocab-size:86 num-oods:1932 (216.835%) most-frequent:\"<OOD>\" 1932 (216.835%)\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\nI0000 00:00:1751261746.865163      35 kernel.cc:818] Configure learner\nI0000 00:00:1751261746.865567      35 kernel.cc:831] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^Age$\"\nfeatures: \"^Cabin$\"\nfeatures: \"^Embarked$\"\nfeatures: \"^Fare$\"\nfeatures: \"^Name$\"\nfeatures: \"^Parch$\"\nfeatures: \"^Pclass$\"\nfeatures: \"^Sex$\"\nfeatures: \"^SibSp$\"\nfeatures: \"^Ticket_item$\"\nfeatures: \"^Ticket_number$\"\nlabel: \"^__LABEL$\"\ntask: CLASSIFICATION\nrandom_seed: 1234\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 2000\n  decision_tree {\n    max_depth: 6\n    min_examples: 1\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    num_candidate_attributes: -1\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      random {\n      }\n    }\n    sparse_oblique_split {\n      num_projections_exponent: 2\n      normalization: MIN_MAX\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n  }\n  shrinkage: 0.05\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  xe_ndcg {\n    ndcg_truncation: 5\n  }\n  stochastic_gradient_boosting {\n    ratio: 1\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  early_stopping_initial_iteration: 10\n}\n\nI0000 00:00:1751261746.865685      35 kernel.cc:834] Deployment config:\ncache_path: \"/tmp/tmpluzonb9v/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\nI0000 00:00:1751261746.865893     399 kernel.cc:895] Train model\nI0000 00:00:1751261747.598284     399 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.05867\nI0000 00:00:1751261747.603901     399 kernel.cc:926] Export model in log directory: /tmp/tmpluzonb9v with prefix 111748d5c31d4165\nI0000 00:00:1751261747.606264     399 kernel.cc:944] Save model in resources\nI0000 00:00:1751261747.608317      35 abstract_model.cc:914] Model self evaluation:\nTask: CLASSIFICATION\nLabel: __LABEL\nLoss (BINOMIAL_LOG_LIKELIHOOD): 1.05867\n\nAccuracy: 0.782609  CI95[W][0 1]\nErrorRate: : 0.217391\n\n\nConfusion Table:\ntruth\\prediction\n    1   2\n1  43   7\n2  13  29\nTotal: 92\n\n\nI0000 00:00:1751261747.639962      35 decision_forest.cc:761] Model loaded with 40 root(s), 2106 node(s), and 10 input feature(s).\nI0000 00:00:1751261747.640009      35 abstract_model.cc:1404] Engine \"GradientBoostedTreesGeneric\" built\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.782608687877655 Loss:1.0586705207824707\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:08.493141Z","iopub.execute_input":"2025-06-30T05:36:08.493513Z","iopub.status.idle":"2025-06-30T05:36:08.508560Z","shell.execute_reply.started":"2025-06-30T05:36:08.493488Z","shell.execute_reply":"2025-06-30T05:36:08.507671Z"}},"outputs":[{"name":"stdout","text":"Model: \"gradient_boosted_trees_model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n=================================================================\nTotal params: 1 (1.00 Byte)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 1 (1.00 Byte)\n_________________________________________________________________\nType: \"GRADIENT_BOOSTED_TREES\"\nTask: CLASSIFICATION\nLabel: \"__LABEL\"\n\nInput Features (11):\n\tAge\n\tCabin\n\tEmbarked\n\tFare\n\tName\n\tParch\n\tPclass\n\tSex\n\tSibSp\n\tTicket_item\n\tTicket_number\n\nNo weights\n\nVariable Importance: INV_MEAN_MIN_DEPTH:\n    1.           \"Sex\"  0.585997 ################\n    2.           \"Age\"  0.364636 #######\n    3.          \"Fare\"  0.266191 ###\n    4.          \"Name\"  0.207054 #\n    5.        \"Pclass\"  0.179191 \n    6. \"Ticket_number\"  0.178806 \n    7.      \"Embarked\"  0.177803 \n    8.   \"Ticket_item\"  0.177009 \n    9.         \"Parch\"  0.175276 \n   10.         \"SibSp\"  0.171694 \n\nVariable Importance: NUM_AS_ROOT:\n    1.  \"Sex\" 34.000000 ################\n    2. \"Name\"  6.000000 \n\nVariable Importance: NUM_NODES:\n    1.           \"Age\" 510.000000 ################\n    2.          \"Fare\" 298.000000 #########\n    3.          \"Name\" 60.000000 #\n    4.   \"Ticket_item\" 47.000000 #\n    5.           \"Sex\" 40.000000 #\n    6.         \"Parch\" 22.000000 \n    7. \"Ticket_number\" 20.000000 \n    8.      \"Embarked\" 15.000000 \n    9.        \"Pclass\" 15.000000 \n   10.         \"SibSp\"  6.000000 \n\nVariable Importance: SUM_SCORE:\n    1.           \"Sex\" 482.453470 ################\n    2.           \"Age\" 390.670218 ############\n    3.          \"Fare\" 321.170935 ##########\n    4.          \"Name\" 102.043860 ###\n    5.        \"Pclass\" 26.605919 \n    6.   \"Ticket_item\" 22.954813 \n    7. \"Ticket_number\" 17.413948 \n    8.      \"Embarked\"  8.969861 \n    9.         \"Parch\"  6.947528 \n   10.         \"SibSp\"  0.455899 \n\n\n\nLoss: BINOMIAL_LOG_LIKELIHOOD\nValidation loss value: 1.05867\nNumber of trees per iteration: 1\nNode format: NOT_SET\nNumber of trees: 40\nTotal number of nodes: 2106\n\nNumber of nodes by tree:\nCount: 40 Average: 52.65 StdDev: 4.2869\nMin: 41 Max: 61 Ignored: 0\n----------------------------------------------\n[ 41, 42)  2   5.00%   5.00% ##\n[ 42, 43)  0   0.00%   5.00%\n[ 43, 44)  0   0.00%   5.00%\n[ 44, 45)  0   0.00%   5.00%\n[ 45, 46)  0   0.00%   5.00%\n[ 46, 47)  0   0.00%   5.00%\n[ 47, 48)  4  10.00%  15.00% ####\n[ 48, 49)  0   0.00%  15.00%\n[ 49, 50)  3   7.50%  22.50% ###\n[ 50, 51)  0   0.00%  22.50%\n[ 51, 52)  4  10.00%  32.50% ####\n[ 52, 53)  0   0.00%  32.50%\n[ 53, 54) 11  27.50%  60.00% ##########\n[ 54, 55)  0   0.00%  60.00%\n[ 55, 56) 10  25.00%  85.00% #########\n[ 56, 57)  0   0.00%  85.00%\n[ 57, 58)  2   5.00%  90.00% ##\n[ 58, 59)  0   0.00%  90.00%\n[ 59, 60)  3   7.50%  97.50% ###\n[ 60, 61]  1   2.50% 100.00% #\n\nDepth by leafs:\nCount: 1073 Average: 4.84623 StdDev: 0.454477\nMin: 2 Max: 5 Ignored: 0\n----------------------------------------------\n[ 2, 3)   1   0.09%   0.09%\n[ 3, 4)  38   3.54%   3.63%\n[ 4, 5)  86   8.01%  11.65% #\n[ 5, 5] 948  88.35% 100.00% ##########\n\nNumber of training obs by leaf:\nCount: 1073 Average: 29.7856 StdDev: 71.8675\nMin: 1 Max: 458 Ignored: 0\n----------------------------------------------\n[   1,  23) 846  78.84%  78.84% ##########\n[  23,  46)  62   5.78%  84.62% #\n[  46,  69)  48   4.47%  89.10% #\n[  69,  92)  21   1.96%  91.05%\n[  92, 115)  10   0.93%  91.99%\n[ 115, 138)  15   1.40%  93.38%\n[ 138, 161)  23   2.14%  95.53%\n[ 161, 184)   6   0.56%  96.09%\n[ 184, 207)   3   0.28%  96.37%\n[ 207, 230)   4   0.37%  96.74%\n[ 230, 252)   1   0.09%  96.83%\n[ 252, 275)   1   0.09%  96.92%\n[ 275, 298)   2   0.19%  97.11%\n[ 298, 321)   2   0.19%  97.30%\n[ 321, 344)   0   0.00%  97.30%\n[ 344, 367)   9   0.84%  98.14%\n[ 367, 390)   6   0.56%  98.70%\n[ 390, 413)   9   0.84%  99.53%\n[ 413, 436)   4   0.37%  99.91%\n[ 436, 458]   1   0.09% 100.00%\n\nAttribute in nodes:\n\t510 : Age [NUMERICAL]\n\t298 : Fare [NUMERICAL]\n\t60 : Name [CATEGORICAL_SET]\n\t47 : Ticket_item [CATEGORICAL]\n\t40 : Sex [CATEGORICAL]\n\t22 : Parch [NUMERICAL]\n\t20 : Ticket_number [CATEGORICAL]\n\t15 : Pclass [NUMERICAL]\n\t15 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 0:\n\t34 : Sex [CATEGORICAL]\n\t6 : Name [CATEGORICAL_SET]\n\nAttribute in nodes with depth <= 1:\n\t48 : Age [NUMERICAL]\n\t34 : Sex [CATEGORICAL]\n\t25 : Fare [NUMERICAL]\n\t6 : Name [CATEGORICAL_SET]\n\t5 : Pclass [NUMERICAL]\n\t2 : Ticket_number [CATEGORICAL]\n\nAttribute in nodes with depth <= 2:\n\t121 : Age [NUMERICAL]\n\t74 : Fare [NUMERICAL]\n\t34 : Sex [CATEGORICAL]\n\t19 : Name [CATEGORICAL_SET]\n\t8 : Ticket_number [CATEGORICAL]\n\t8 : Embarked [CATEGORICAL]\n\t6 : Pclass [NUMERICAL]\n\t6 : Parch [NUMERICAL]\n\t3 : Ticket_item [CATEGORICAL]\n\nAttribute in nodes with depth <= 3:\n\t261 : Age [NUMERICAL]\n\t164 : Fare [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t35 : Name [CATEGORICAL_SET]\n\t16 : Ticket_item [CATEGORICAL]\n\t13 : Ticket_number [CATEGORICAL]\n\t12 : Embarked [CATEGORICAL]\n\t11 : Parch [NUMERICAL]\n\t9 : Pclass [NUMERICAL]\n\t2 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 5:\n\t510 : Age [NUMERICAL]\n\t298 : Fare [NUMERICAL]\n\t60 : Name [CATEGORICAL_SET]\n\t47 : Ticket_item [CATEGORICAL]\n\t40 : Sex [CATEGORICAL]\n\t22 : Parch [NUMERICAL]\n\t20 : Ticket_number [CATEGORICAL]\n\t15 : Pclass [NUMERICAL]\n\t15 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nCondition type in nodes:\n\t851 : ObliqueCondition\n\t135 : ContainsBitmapCondition\n\t47 : ContainsCondition\nCondition type in nodes with depth <= 0:\n\t38 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 1:\n\t78 : ObliqueCondition\n\t40 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 2:\n\t207 : ObliqueCondition\n\t58 : ContainsBitmapCondition\n\t14 : ContainsCondition\nCondition type in nodes with depth <= 3:\n\t447 : ObliqueCondition\n\t83 : ContainsBitmapCondition\n\t29 : ContainsCondition\nCondition type in nodes with depth <= 5:\n\t851 : ObliqueCondition\n\t135 : ContainsBitmapCondition\n\t47 : ContainsCondition\n\nTraining logs:\nNumber of iteration to final model: 40\n\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n\tIter:26 train-loss:0.647960 valid-loss:1.065191  train-accuracy:0.922403 valid-accuracy:0.782609\n\tIter:36 train-loss:0.557737 valid-loss:1.071260  train-accuracy:0.922403 valid-accuracy:0.782609\n\tIter:46 train-loss:0.494259 valid-loss:1.063639  train-accuracy:0.927409 valid-accuracy:0.771739\n\tIter:56 train-loss:0.443537 valid-loss:1.070069  train-accuracy:0.939925 valid-accuracy:0.760870\n\tIter:66 train-loss:0.404514 valid-loss:1.081874  train-accuracy:0.949937 valid-accuracy:0.760870\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def prediction_to_kaggle_format(model, threshold=0.5):\n    proba_survive = model.predict(serving_ds, verbose=0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\": serving_df[\"PassengerId\"],\n        \"Survived\": (proba_survive >= threshold).astype(int)\n    })\n\ndef make_submission(kaggle_predictions):\n    path=\"/kaggle/working/submission.csv\"\n    kaggle_predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n    \nkaggle_predictions = prediction_to_kaggle_format(model)\nmake_submission(kaggle_predictions)\n!head /kaggle/working/submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:36:24.717480Z","iopub.execute_input":"2025-06-30T05:36:24.718132Z","iopub.status.idle":"2025-06-30T05:36:25.051461Z","shell.execute_reply.started":"2025-06-30T05:36:24.718106Z","shell.execute_reply":"2025-06-30T05:36:25.050152Z"}},"outputs":[{"name":"stdout","text":"Submission exported to /kaggle/working/submission.csv\nPassengerId,Survived\n892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"tuner = tfdf.tuner.RandomSearch(num_trials=1000)\ntuner.choice(\"min_examples\", [2, 5, 7, 10])\ntuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n\nlocal_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\nlocal_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n\nglobal_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\nglobal_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n\n#tuner.choice(\"use_hessian_gain\", [True, False])\ntuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\ntuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n\n\ntuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\noblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\noblique_space.choice(\"sparse_oblique_normalization\",\n                     [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\noblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\noblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\ntuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\ntuned_model.fit(train_ds, verbose=0)\n\ntuned_self_evaluation = tuned_model.make_inspector().evaluation()\nprint(f\"Accuracy: {tuned_self_evaluation.accuracy} Loss:{tuned_self_evaluation.loss}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:37:47.937434Z","iopub.execute_input":"2025-06-30T05:37:47.937831Z","iopub.status.idle":"2025-06-30T05:37:47.975115Z","shell.execute_reply.started":"2025-06-30T05:37:47.937808Z","shell.execute_reply":"2025-06-30T05:37:47.973338Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/163988637.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moblique_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse_oblique_weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"BINARY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CONTINUOUS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moblique_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse_oblique_num_projections_exponent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtuned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostedTreesModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mtuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_decision_forests/keras/core.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kargs)\u001b[0m\n\u001b[1;32m   2308\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m     )\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_decision_forests/keras/wrappers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task, features, exclude_non_specified_features, preprocessing, postprocessing, training_preprocessing, ranking_group, uplift_treatment, temp_directory, verbose, hyperparameter_template, advanced_arguments, num_threads, name, max_vocab_count, try_resume_training, check_dataset, tuner, discretize_numerical_features, num_discretized_numerical_bins, multitask, adapt_subsample_for_maximum_training_duration, allow_na_conditions, apply_link_function, categorical_algorithm, categorical_set_split_greedy_sampling, categorical_set_split_max_num_items, categorical_set_split_min_item_frequency, compute_permutation_variable_importance, cross_entropy_ndcg_truncation, dart_dropout, early_stopping, early_stopping_initial_iteration, early_stopping_num_trees_look_ahead, focal_loss_alpha, focal_loss_gamma, forest_extraction, goss_alpha, goss_beta, growing_strategy, honest, honest_fixed_separation, honest_ratio_leaf_examples, in_split_min_examples_check, keep_non_leaf_label_distribution, l1_regularization, l2_categorical_regularization, l2_regularization, lambda_loss, loss, max_depth, max_num_nodes, maximum_model_size_in_memory_in_bytes, maximum_training_duration_seconds, mhld_oblique_max_num_attributes, mhld_oblique_sample_attributes, min_examples, missing_value_policy, ndcg_truncation, num_candidate_attributes, num_candidate_attributes_ratio, num_trees, pure_serving_model, random_seed, sampling_method, selective_gradient_boosting_ratio, shrinkage, sorting_strategy, sparse_oblique_max_num_projections, sparse_oblique_normalization, sparse_oblique_num_projections_exponent, sparse_oblique_projection_density_factor, sparse_oblique_weights, split_axis, subsample, uplift_min_examples_in_treatment, uplift_split_score, use_hessian_gain, validation_interval_in_trees, validation_ratio, explicit_args)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         explicit_args)\n\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m     super(GradientBoostedTreesModel, self).__init__(task=task,\n\u001b[0m\u001b[1;32m   1469\u001b[0m       \u001b[0mlearner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRADIENT_BOOSTED_TREES\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0mlearner_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearner_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_decision_forests/keras/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task, learner, learner_params, features, exclude_non_specified_features, preprocessing, postprocessing, training_preprocessing, ranking_group, uplift_treatment, temp_directory, verbose, advanced_arguments, num_threads, name, max_vocab_count, try_resume_training, check_dataset, tuner, discretize_numerical_features, num_discretized_numerical_bins, multitask)\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mmultitask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMultiTaskItem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   ) -> None:\n\u001b[0;32m--> 524\u001b[0;31m     super(CoreModel, self).__init__(\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_decision_forests/keras/core_inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task, ranking_group, verbose, advanced_arguments, name, preprocessing, postprocessing, uplift_treatment, temp_directory, multitask, tuner, learner)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Multi-task learning is not compatible with the tuner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_base_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m       \u001b[0mtraining_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_multitask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0mtraining_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MULTITASKER\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m   1332\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;31m# Construct a new object to represent this field.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m             \u001b[0mfield_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m             \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m           \u001b[0mfield_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'FieldDescriptor' object has no attribute '_default_constructor'"],"ename":"AttributeError","evalue":"'FieldDescriptor' object has no attribute '_default_constructor'","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"import tensorflow_decision_forests as tfdf\nimport protobuf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T05:38:31.967016Z","iopub.execute_input":"2025-06-30T05:38:31.967324Z","iopub.status.idle":"2025-06-30T05:38:31.988662Z","shell.execute_reply.started":"2025-06-30T05:38:31.967304Z","shell.execute_reply":"2025-06-30T05:38:31.987065Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/704774172.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_decision_forests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprotobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'protobuf'"],"ename":"ModuleNotFoundError","evalue":"No module named 'protobuf'","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}